{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Parsera Scraping Notebook**\n",
        "\n",
        "This notebook demonstrates how to use the Parsera library to scrape AI news from Wired.\n",
        "It uses a language model to interpret and extract specific elements from the webpage.\n",
        "\n",
        "https://github.com/raznem/parsera\n"
      ],
      "metadata": {
        "id": "--To-2dWBVri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup and Installation ---\n",
        "# Install required libraries\n",
        "!pip install parsera langchain-together -q\n",
        "!playwright install -q"
      ],
      "metadata": {
        "id": "UzunZ-25BjHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply nest_asyncio to allow asynchronous operations in Jupyter\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Environment Setup ---\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set up the API key (make sure to add this to your Colab secrets)\n",
        "os.environ[\"TOGETHER_API_KEY\"] = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "# --- Imports ---\n",
        "from parsera import Parsera\n",
        "from langchain_together import ChatTogether"
      ],
      "metadata": {
        "id": "hE-D8gTSBiFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Language Model Configuration ---\n",
        "# Initialize the language model\n",
        "llm = ChatTogether(\n",
        "    model=\"google/gemma-2-9b-it\",\n",
        "    temperature=0.2,\n",
        "    together_api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
        ")"
      ],
      "metadata": {
        "id": "ssfvAZrTCAYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Web Scraping Configuration ---\n",
        "# Define the URL to scrape\n",
        "url = \"https://www.wired.com/tag/artificial-intelligence/?page=1\""
      ],
      "metadata": {
        "id": "N8e7NAk4Cfkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the elements to extract\n",
        "elements = {\n",
        "    \"Title\": \"News title\",\n",
        "    \"URL\": \"URL of the Article\",\n",
        "}"
      ],
      "metadata": {
        "id": "X1ap4O2nChaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhk6_-99BTnO"
      },
      "outputs": [],
      "source": [
        "# --- Scraping Execution ---\n",
        "# Initialize the Parsera scraper with our language model\n",
        "scraper = Parsera(model=llm)\n",
        "\n",
        "# Run the scraping operation\n",
        "result = scraper.run(url=url, elements=elements)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Results ---\n",
        "print(\"Scraped AI News from Wired:\")\n",
        "for item in result:\n",
        "    print(f\"Title: {item['Title']}\")\n",
        "    print(f\"URL: {item['URL']}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "h0fe0aD6Cks_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}