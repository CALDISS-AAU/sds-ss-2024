{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMKWODdRvs-M"
      },
      "source": [
        "# Zero-shot with LLM, SetFit and Argilla\n",
        "\n",
        "This tutorial covers text classification using zero-shot LLM labeling through the Together API. We then use traditional machine learning techniques with TF-IDF vectorization and logistic regression - for comparaison. The idea here is to have the LLM prelabel our dataset. We then use Argilla to check if the model provided good labels. There are variations to that approach - including Bart Models (multi-label-zero-shot).\n",
        "\n",
        "**Using OpenAI-style API via the Together API:**\n",
        "\n",
        "1. **Model Configuration**: A system prompt is defined, outlining the task of categorizing news articles into predefined categories: \"World\", \"Sports\", \"Business\", and \"Sci/Tech\". The output is required to adhere strictly to the JSON format.\n",
        "\n",
        "2. **Text Classification**: The provided text is classified into one of the predefined categories using an open source LLM model.\n",
        "\n",
        "3. **Evaluation**: The classified data is evaluated by predicting categories for a sample of news articles and comparing the predictions with ground truth annotations.\n",
        "\n",
        "**Traditional Machine Learning Approach:**\n",
        "\n",
        "We compare the results from the 0-shot/few-shot approach with a traditional ML/NLP approach, where we will be using a very large training dataset.\n",
        "\n",
        "**Comparison with Traditional Machine Learning Approach:**\n",
        "\n",
        "Both approaches aim to classify news articles into predefined categories, but they differ in their underlying methodologies. The LLM based approach leverages a state-of-the-art language model for text classification, while the traditional machine learning approach relies on TF-IDF vectorization and logistic regression (but requires much more data for training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbVZwhkomZj7"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.39.0"
      ],
      "metadata": {
        "id": "dtIK6Mcn4qzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-k1rf8VpIqY"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFjALvYppLAe"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Dict"
      ],
      "metadata": {
        "id": "BWxI8yAlw8Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iS2wg9Yk5tZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM1kq7PaoAwr"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "\n",
        "You are a sophisticated classification engine tasked with categorizing news articles.\n",
        "Your primary function is to evaluate the core message of each article and assign it to one of the following categories: \"World\" for global news covering politics and similar topics,\n",
        "\"Sports\" for news related to sports, \"Business\" for articles on business, economics, or finance,\n",
        "and \"Sci/Tech\" for content focused on technology and science. Upon analyzing a text input, you will provide an explanation for the category chosen - very short.\n",
        " Your output will adhere strictly to the JSON format, specifically:\n",
        " {\"prediction\":\"your selected prediction\", \"explanation\":\"your explanation\"}.\n",
        " It is imperative that your output is VALID JSON and contains no other elements. Output it as string not markdown or code.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suiAdQlHrPw1"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Stocks Rally on Lower Oil Prices Stocks rallied in quiet trading Wednesday\n",
        "as lower oil prices brought out buyers, countering a pair of government reports\n",
        "that gave a mixed picture of the economy.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionOutcome(BaseModel):\n",
        "    prediction: str = Field(description=\"Your selected prediction\")\n",
        "    explanation: str = Field(description=\"Your explanation\")"
      ],
      "metadata": {
        "id": "yYmShc7gxRLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVs7ZbX_ujPD"
      },
      "outputs": [],
      "source": [
        "# Point to the local server\n",
        "client = OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=TOGETHER_API_KEY)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\", # this field is currently unused\n",
        "  response_format={\"type\": \"json_object\", \"schema\": PredictionOutcome.model_json_schema()},\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": f'Classify following text: {text}'}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6S1muwtsMIb"
      },
      "outputs": [],
      "source": [
        "json.loads(completion.choices[0].message.content.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRvGQXKhpyT3"
      },
      "outputs": [],
      "source": [
        "def classify(text):\n",
        "  completion = client.chat.completions.create(\n",
        "  model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\", # this field is currently unused\n",
        "  response_format={\"type\": \"json_object\", \"schema\": PredictionOutcome.model_json_schema()},\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": f'Classify following text: {text}'}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        ")\n",
        "  json_response = completion.choices[0].message.content.strip()\n",
        "  try:\n",
        "        prediction = json.loads(json_response)\n",
        "  except:\n",
        "        # for some examples, json is not correctly formatted\n",
        "        return {\"prediction\": None, \"explanation\": f\"Wrong JSON format: {json_response}\" }\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fb9A6EQsrLe"
      },
      "outputs": [],
      "source": [
        "classify(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlhsDEP8d5Gv"
      },
      "outputs": [],
      "source": [
        "!pip install setfit datasets -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81yIZzcO3QQb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn9PnPQofGb7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the data\n",
        "data_train = pd.read_parquet('https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/ag_news_unlabelled.pq')\n",
        "\n",
        "# Convert to Hugging Face dataset\n",
        "dataset_news = Dataset.from_pandas(data_train.sample(30).reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mXWvnq5tIwc"
      },
      "outputs": [],
      "source": [
        "# let's predict over the test set to eval our zero-shot classifier\n",
        "train_ds_with_preds = dataset_news.map(lambda example: classify(example[\"text\"]))\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "train_ds_with_preds.to_pandas().head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmAMNA_Kg-O5"
      },
      "outputs": [],
      "source": [
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize SetFitModel\n",
        "model = SetFitModel.from_pretrained(\"intfloat/multilingual-e5-base\").to('cuda')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn the dataframe train_ds_with_preds.to_pandas() into a HF dataset for training\n",
        "train_ds = Dataset.from_pandas(train_ds_with_preds.to_pandas())"
      ],
      "metadata": {
        "id": "IzMoobVyyWg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb7ti_NViCy6"
      },
      "outputs": [],
      "source": [
        "# Load the handlabelled dataset from Argilla\n",
        "test_ds = load_dataset(\"ag_news\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel"
      ],
      "metadata": {
        "id": "2iYOMAqWzSbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-4sWjv4ibfu"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "id": "LIqQ-UtayvlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrLrXDx4kK7p"
      },
      "outputs": [],
      "source": [
        "test_ds.features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new feature \"label_orig\" and copy \"label\" into it\n",
        "train_ds_with_preds = train_ds_with_preds.map(lambda example: {\"label_orig\": example[\"label\"]})"
      ],
      "metadata": {
        "id": "27lmsl7t1f6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'World', 'Sports', 'Business', 'Sci/Tech' correspond to labels from 0 to 3 - create a mapping and write the numerical values corresponding to \"prediction\" into it\n",
        "label_mapping = {\n",
        "    'World': 0,\n",
        "    'Sports': 1,\n",
        "    'Business': 2,\n",
        "    'Sci/Tech': 3\n",
        "}\n",
        "\n",
        "# Apply the mapping to the 'prediction' column\n",
        "train_ds_with_preds = train_ds_with_preds.map(lambda example: {\"label\": label_mapping[example[\"prediction\"]]})"
      ],
      "metadata": {
        "id": "ZgffHQ631gwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89GuT0flhkgT"
      },
      "outputs": [],
      "source": [
        "# Preparing the training arguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    batch_size=16,\n",
        "    num_epochs=5,\n",
        ")\n",
        "\n",
        "\n",
        "# Create SetFitTrainer and train\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds_with_preds,\n",
        "    eval_dataset=test_ds,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHe23Czflnyi"
      },
      "outputs": [],
      "source": [
        "# Predict and evaluate\n",
        "predicted_labels = model.predict(test_ds['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uTZ0Kt6mP0H"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_ds['label'], predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEjb32vIkknM"
      },
      "outputs": [],
      "source": [
        "# Load AG News dataset for logistic regression\n",
        "dataset = load_dataset(\"ag_news\", split={'train': 'train', 'test': 'test'})\n",
        "\n",
        "# Training and test sets\n",
        "train_texts = dataset['train']['text']\n",
        "train_labels = dataset['train']['label']\n",
        "test_texts = dataset['test']['text']\n",
        "test_labels = dataset['test']['label']\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "model_lg = make_pipeline(TfidfVectorizer(stop_words='english'), LogisticRegression(max_iter=1000))\n",
        "model_lg.fit(train_texts, train_labels)\n",
        "\n",
        "# Predict and evaluate\n",
        "predicted_labels = model_lg.predict(test_texts)\n",
        "print(classification_report(test_labels, predicted_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}